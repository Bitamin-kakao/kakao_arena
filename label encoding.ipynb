{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>like_cnt</th>\n",
       "      <th>plylst_title</th>\n",
       "      <th>songs</th>\n",
       "      <th>tags</th>\n",
       "      <th>updt_date</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61281</td>\n",
       "      <td>71</td>\n",
       "      <td>여행같은 음악</td>\n",
       "      <td>[525514, 129701, 383374, 562083, 297861, 13954...</td>\n",
       "      <td>[락]</td>\n",
       "      <td>2013-12-19 18:36:19.000</td>\n",
       "      <td>[J-POP, 일렉트로니카, R&amp;B/Soul, POP, 포크/블루스/컨트리, 록/메탈]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10532</td>\n",
       "      <td>1</td>\n",
       "      <td>요즘 너 말야</td>\n",
       "      <td>[432406, 675945, 497066, 120377, 389529, 24427...</td>\n",
       "      <td>[추억, 회상]</td>\n",
       "      <td>2014-12-02 16:19:42.000</td>\n",
       "      <td>[포크/블루스, 일렉트로니카, 재즈, 뉴에이지, POP, OST, 발라드, 록/메탈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76951</td>\n",
       "      <td>17</td>\n",
       "      <td>편하게, 잔잔하게 들을 수 있는 곡.-</td>\n",
       "      <td>[83116, 276692, 166267, 186301, 354465, 256598...</td>\n",
       "      <td>[까페, 잔잔한]</td>\n",
       "      <td>2017-08-28 07:09:34.000</td>\n",
       "      <td>[포크/블루스, 랩/힙합, 재즈, 일렉트로니카, R&amp;B/Soul, 발라드, 록/메탈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147456</td>\n",
       "      <td>33</td>\n",
       "      <td>크리스마스 분위기에 흠뻑 취하고 싶을때</td>\n",
       "      <td>[394031, 195524, 540149, 287984, 440773, 10033...</td>\n",
       "      <td>[연말, 눈오는날, 캐럴, 분위기, 따듯한, 크리스마스캐럴, 겨울노래, 크리스마스,...</td>\n",
       "      <td>2019-12-05 15:15:18.000</td>\n",
       "      <td>[성인가요, 포크/블루스, 재즈, 어린이/태교, POP, R&amp;B/Soul, 뉴에이지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27616</td>\n",
       "      <td>9</td>\n",
       "      <td>추억의 노래 ㅋ</td>\n",
       "      <td>[159327, 553610, 5130, 645103, 294435, 100657,...</td>\n",
       "      <td>[댄스]</td>\n",
       "      <td>2011-10-25 13:54:56.000</td>\n",
       "      <td>[랩/힙합, R&amp;B/Soul, 발라드, 댄스, 록/메탈, 아이돌]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  like_cnt           plylst_title  \\\n",
       "0   61281        71                여행같은 음악   \n",
       "1   10532         1                요즘 너 말야   \n",
       "2   76951        17  편하게, 잔잔하게 들을 수 있는 곡.-   \n",
       "3  147456        33  크리스마스 분위기에 흠뻑 취하고 싶을때   \n",
       "4   27616         9               추억의 노래 ㅋ   \n",
       "\n",
       "                                               songs  \\\n",
       "0  [525514, 129701, 383374, 562083, 297861, 13954...   \n",
       "1  [432406, 675945, 497066, 120377, 389529, 24427...   \n",
       "2  [83116, 276692, 166267, 186301, 354465, 256598...   \n",
       "3  [394031, 195524, 540149, 287984, 440773, 10033...   \n",
       "4  [159327, 553610, 5130, 645103, 294435, 100657,...   \n",
       "\n",
       "                                                tags                updt_date  \\\n",
       "0                                                [락]  2013-12-19 18:36:19.000   \n",
       "1                                           [추억, 회상]  2014-12-02 16:19:42.000   \n",
       "2                                          [까페, 잔잔한]  2017-08-28 07:09:34.000   \n",
       "3  [연말, 눈오는날, 캐럴, 분위기, 따듯한, 크리스마스캐럴, 겨울노래, 크리스마스,...  2019-12-05 15:15:18.000   \n",
       "4                                               [댄스]  2011-10-25 13:54:56.000   \n",
       "\n",
       "                                               genre  \n",
       "0   [J-POP, 일렉트로니카, R&B/Soul, POP, 포크/블루스/컨트리, 록/메탈]  \n",
       "1  [포크/블루스, 일렉트로니카, 재즈, 뉴에이지, POP, OST, 발라드, 록/메탈...  \n",
       "2  [포크/블루스, 랩/힙합, 재즈, 일렉트로니카, R&B/Soul, 발라드, 록/메탈...  \n",
       "3  [성인가요, 포크/블루스, 재즈, 어린이/태교, POP, R&B/Soul, 뉴에이지...  \n",
       "4               [랩/힙합, R&B/Soul, 발라드, 댄스, 록/메탈, 아이돌]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(\"E:/Kakao Arena\")\n",
    "\n",
    "def load_json(fname):\n",
    "    with open(fname, encoding=\"utf-8\") as f:\n",
    "        json_obj = json.load(f)\n",
    "\n",
    "    return json_obj\n",
    "\n",
    "song = pd.DataFrame(load_json(\"song_meta.json\"))\n",
    "val = pd.DataFrame(load_json(\"val.json\"))\n",
    "import pickle\n",
    "with open(\"train_genre.pickle\",\"rb\")as fr:\n",
    "    train_genre = pickle.load(fr)\n",
    "train_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707989"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115071"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_range = []\n",
    "for i in range(len(train_genre)):\n",
    "    tmp_range.append(len(train_genre[\"songs\"][i]))\n",
    "max(tmp_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "train_songs = [[]]\n",
    "\n",
    "for i in range(len(train_genre[\"songs\"])):\n",
    "    while (len(train_songs[i]) < 200) and (200 - len(train_songs[i]) > len(train_genre[\"songs\"][i])):\n",
    "        train_songs[i].extend(train_genre[\"songs\"][i])\n",
    "    \n",
    "    train_songs[i].extend(random.sample(train_genre[\"songs\"][i],200 - len(train_songs[i])))\n",
    "    train_songs.append([])\n",
    "    #print(i)\n",
    "    \n",
    "del train_songs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_songs_df = pd.DataFrame(train_songs) / (len(song)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "      <td>115071.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.499642</td>\n",
       "      <td>0.501604</td>\n",
       "      <td>0.498623</td>\n",
       "      <td>0.498315</td>\n",
       "      <td>0.500385</td>\n",
       "      <td>0.496912</td>\n",
       "      <td>0.499301</td>\n",
       "      <td>0.500209</td>\n",
       "      <td>0.499879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499560</td>\n",
       "      <td>0.501428</td>\n",
       "      <td>0.500536</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.499871</td>\n",
       "      <td>0.501155</td>\n",
       "      <td>0.500878</td>\n",
       "      <td>0.500829</td>\n",
       "      <td>0.500772</td>\n",
       "      <td>0.500494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.288365</td>\n",
       "      <td>0.288520</td>\n",
       "      <td>0.289265</td>\n",
       "      <td>0.288667</td>\n",
       "      <td>0.288355</td>\n",
       "      <td>0.289907</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>0.288665</td>\n",
       "      <td>0.288251</td>\n",
       "      <td>0.289203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288758</td>\n",
       "      <td>0.289040</td>\n",
       "      <td>0.288673</td>\n",
       "      <td>0.289837</td>\n",
       "      <td>0.288501</td>\n",
       "      <td>0.288968</td>\n",
       "      <td>0.289787</td>\n",
       "      <td>0.288740</td>\n",
       "      <td>0.289834</td>\n",
       "      <td>0.288978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.249949</td>\n",
       "      <td>0.249206</td>\n",
       "      <td>0.248530</td>\n",
       "      <td>0.247189</td>\n",
       "      <td>0.246113</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.245018</td>\n",
       "      <td>0.247593</td>\n",
       "      <td>0.248960</td>\n",
       "      <td>0.247609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247528</td>\n",
       "      <td>0.250784</td>\n",
       "      <td>0.249266</td>\n",
       "      <td>0.247080</td>\n",
       "      <td>0.249092</td>\n",
       "      <td>0.250654</td>\n",
       "      <td>0.247528</td>\n",
       "      <td>0.250654</td>\n",
       "      <td>0.247603</td>\n",
       "      <td>0.249399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.503247</td>\n",
       "      <td>0.500939</td>\n",
       "      <td>0.503872</td>\n",
       "      <td>0.499037</td>\n",
       "      <td>0.497620</td>\n",
       "      <td>0.502186</td>\n",
       "      <td>0.494809</td>\n",
       "      <td>0.501069</td>\n",
       "      <td>0.504407</td>\n",
       "      <td>0.499660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502934</td>\n",
       "      <td>0.503445</td>\n",
       "      <td>0.502617</td>\n",
       "      <td>0.501472</td>\n",
       "      <td>0.500939</td>\n",
       "      <td>0.500870</td>\n",
       "      <td>0.503177</td>\n",
       "      <td>0.503268</td>\n",
       "      <td>0.502445</td>\n",
       "      <td>0.500939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.750308</td>\n",
       "      <td>0.749991</td>\n",
       "      <td>0.754646</td>\n",
       "      <td>0.751171</td>\n",
       "      <td>0.748575</td>\n",
       "      <td>0.752679</td>\n",
       "      <td>0.749915</td>\n",
       "      <td>0.749862</td>\n",
       "      <td>0.748725</td>\n",
       "      <td>0.751605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750099</td>\n",
       "      <td>0.751917</td>\n",
       "      <td>0.751915</td>\n",
       "      <td>0.751586</td>\n",
       "      <td>0.750197</td>\n",
       "      <td>0.753438</td>\n",
       "      <td>0.753381</td>\n",
       "      <td>0.751555</td>\n",
       "      <td>0.752662</td>\n",
       "      <td>0.751605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0              1              2              3    \\\n",
       "count  115071.000000  115071.000000  115071.000000  115071.000000   \n",
       "mean        0.500044       0.499642       0.501604       0.498623   \n",
       "std         0.288365       0.288520       0.289265       0.288667   \n",
       "min         0.000007       0.000013       0.000076       0.000027   \n",
       "25%         0.249949       0.249206       0.248530       0.247189   \n",
       "50%         0.503247       0.500939       0.503872       0.499037   \n",
       "75%         0.750308       0.749991       0.754646       0.751171   \n",
       "max         0.999968       0.999968       0.999997       0.999955   \n",
       "\n",
       "                 4              5              6              7    \\\n",
       "count  115071.000000  115071.000000  115071.000000  115071.000000   \n",
       "mean        0.498315       0.500385       0.496912       0.499301   \n",
       "std         0.288355       0.289907       0.289062       0.288665   \n",
       "min         0.000024       0.000014       0.000045       0.000014   \n",
       "25%         0.246113       0.248133       0.245018       0.247593   \n",
       "50%         0.497620       0.502186       0.494809       0.501069   \n",
       "75%         0.748575       0.752679       0.749915       0.749862   \n",
       "max         0.999996       0.999997       0.999968       0.999944   \n",
       "\n",
       "                 8              9    ...            190            191  \\\n",
       "count  115071.000000  115071.000000  ...  115071.000000  115071.000000   \n",
       "mean        0.500209       0.499879  ...       0.499560       0.501428   \n",
       "std         0.288251       0.289203  ...       0.288758       0.289040   \n",
       "min         0.000042       0.000004  ...       0.000032       0.000000   \n",
       "25%         0.248960       0.247609  ...       0.247528       0.250784   \n",
       "50%         0.504407       0.499660  ...       0.502934       0.503445   \n",
       "75%         0.748725       0.751605  ...       0.750099       0.751917   \n",
       "max         0.999983       0.999975  ...       0.999997       0.999997   \n",
       "\n",
       "                 192            193            194            195  \\\n",
       "count  115071.000000  115071.000000  115071.000000  115071.000000   \n",
       "mean        0.500536       0.499989       0.499871       0.501155   \n",
       "std         0.288673       0.289837       0.288501       0.288968   \n",
       "min         0.000007       0.000014       0.000013       0.000027   \n",
       "25%         0.249266       0.247080       0.249092       0.250654   \n",
       "50%         0.502617       0.501472       0.500939       0.500870   \n",
       "75%         0.751915       0.751586       0.750197       0.753438   \n",
       "max         0.999996       0.999980       0.999969       0.999992   \n",
       "\n",
       "                 196            197            198            199  \n",
       "count  115071.000000  115071.000000  115071.000000  115071.000000  \n",
       "mean        0.500878       0.500829       0.500772       0.500494  \n",
       "std         0.289787       0.288740       0.289834       0.288978  \n",
       "min         0.000007       0.000014       0.000038       0.000007  \n",
       "25%         0.247528       0.250654       0.247603       0.249399  \n",
       "50%         0.503177       0.503268       0.502445       0.500939  \n",
       "75%         0.753381       0.751555       0.752662       0.751605  \n",
       "max         0.999989       0.999999       0.999996       0.999968  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_songs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_songs = np.asarray(train_songs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x = train_test_split(train_songs_df, test_size=0.3, shuffle=True, random_state=1234)\n",
    "train_x = np.asarray(train_x)\n",
    "test_x = np.asarray(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80549 samples, validate on 34522 samples\n",
      "Epoch 1/100\n",
      "80549/80549 [==============================] - 2s 22us/sample - loss: 0.0797 - val_loss: 0.0759\n",
      "Epoch 2/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0743 - val_loss: 0.0732\n",
      "Epoch 3/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0729 - val_loss: 0.0725\n",
      "Epoch 4/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0723 - val_loss: 0.0721\n",
      "Epoch 5/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0720 - val_loss: 0.0719\n",
      "Epoch 6/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0718 - val_loss: 0.0716\n",
      "Epoch 7/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0714 - val_loss: 0.0713\n",
      "Epoch 8/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0712 - val_loss: 0.0711\n",
      "Epoch 9/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0710 - val_loss: 0.0709\n",
      "Epoch 10/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0709 - val_loss: 0.0708\n",
      "Epoch 11/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0708 - val_loss: 0.0708\n",
      "Epoch 12/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0708 - val_loss: 0.0707\n",
      "Epoch 13/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0707 - val_loss: 0.0707\n",
      "Epoch 14/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0707 - val_loss: 0.0706\n",
      "Epoch 15/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0706 - val_loss: 0.0706\n",
      "Epoch 16/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0706 - val_loss: 0.0706\n",
      "Epoch 17/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0706 - val_loss: 0.0705\n",
      "Epoch 18/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0705 - val_loss: 0.0705\n",
      "Epoch 19/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0705 - val_loss: 0.0705\n",
      "Epoch 20/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0705 - val_loss: 0.0705\n",
      "Epoch 21/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0705 - val_loss: 0.0705\n",
      "Epoch 22/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0704 - val_loss: 0.0704\n",
      "Epoch 23/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0704 - val_loss: 0.0705\n",
      "Epoch 24/100\n",
      "80549/80549 [==============================] - 1s 8us/sample - loss: 0.0704 - val_loss: 0.0704\n",
      "Epoch 25/100\n",
      "80549/80549 [==============================] - 1s 9us/sample - loss: 0.0704 - val_loss: 0.0704\n",
      "Epoch 26/100\n",
      "80549/80549 [==============================] - 1s 8us/sample - loss: 0.0704 - val_loss: 0.0704\n",
      "Epoch 27/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0704 - val_loss: 0.0704\n",
      "Epoch 28/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0704 - val_loss: 0.0704\n",
      "Epoch 29/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0703 - val_loss: 0.0704\n",
      "Epoch 30/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0703 - val_loss: 0.0703\n",
      "Epoch 31/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0703 - val_loss: 0.0703\n",
      "Epoch 32/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0703 - val_loss: 0.0703\n",
      "Epoch 33/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0703 - val_loss: 0.0703\n",
      "Epoch 34/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0703 - val_loss: 0.0703\n",
      "Epoch 35/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0703 - val_loss: 0.0703\n",
      "Epoch 36/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0702 - val_loss: 0.0703\n",
      "Epoch 37/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0702 - val_loss: 0.0703\n",
      "Epoch 38/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0702 - val_loss: 0.0702\n",
      "Epoch 39/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0702 - val_loss: 0.0702\n",
      "Epoch 40/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0701 - val_loss: 0.0702\n",
      "Epoch 41/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0701 - val_loss: 0.0701\n",
      "Epoch 42/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0701 - val_loss: 0.0702\n",
      "Epoch 43/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0701 - val_loss: 0.0701\n",
      "Epoch 44/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0701 - val_loss: 0.0701\n",
      "Epoch 45/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0701 - val_loss: 0.0702\n",
      "Epoch 46/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0700 - val_loss: 0.0700\n",
      "Epoch 47/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0700 - val_loss: 0.0700\n",
      "Epoch 48/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0700 - val_loss: 0.0700\n",
      "Epoch 49/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0700 - val_loss: 0.0700\n",
      "Epoch 50/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0700 - val_loss: 0.0700\n",
      "Epoch 51/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0699 - val_loss: 0.0699\n",
      "Epoch 52/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0699 - val_loss: 0.0699\n",
      "Epoch 53/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0699 - val_loss: 0.0700\n",
      "Epoch 54/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0699 - val_loss: 0.0699\n",
      "Epoch 55/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0699 - val_loss: 0.0699\n",
      "Epoch 56/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0699 - val_loss: 0.0699\n",
      "Epoch 57/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0698 - val_loss: 0.0699\n",
      "Epoch 58/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0698 - val_loss: 0.0698\n",
      "Epoch 59/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0698 - val_loss: 0.0698\n",
      "Epoch 60/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0698 - val_loss: 0.0699\n",
      "Epoch 61/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0698 - val_loss: 0.0698\n",
      "Epoch 62/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0698 - val_loss: 0.0698\n",
      "Epoch 63/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0698 - val_loss: 0.0698\n",
      "Epoch 64/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0698\n",
      "Epoch 65/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0698\n",
      "Epoch 66/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0698\n",
      "Epoch 67/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0698\n",
      "Epoch 68/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0697\n",
      "Epoch 69/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0697\n",
      "Epoch 70/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0697\n",
      "Epoch 71/100\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0697\n",
      "Epoch 72/100\n",
      "74983/80549 [==========================>...] - ETA: 0s - loss: 0.0697Restoring model weights from the end of the best epoch.\n",
      "80549/80549 [==============================] - 1s 7us/sample - loss: 0.0697 - val_loss: 0.0698\n",
      "Epoch 00072: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26bab8f4ec8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            min_delta = 0.0001, \n",
    "                                            patience=10, \n",
    "                                            verbose = True, \n",
    "                                            restore_best_weights = True)\n",
    "\n",
    "x = tf.keras.Input(shape=(len(train_songs_df.columns),))\n",
    "\n",
    "encoded = tf.keras.layers.Dense(100,activation='relu')(x)\n",
    "encoded = tf.keras.layers.Dense(30,activation='relu')(encoded)\n",
    "encoded = tf.keras.layers.Dense(15,activation='relu')(encoded)\n",
    "\n",
    "decoded = tf.keras.layers.Dense(30,activation='relu')(encoded)\n",
    "decoded = tf.keras.layers.Dense(100,activation='relu')(decoded)\n",
    "decoded = tf.keras.layers.Dense(len(train_songs_df.columns),activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder_tr = tf.keras.models.Model(x,decoded)\n",
    "\n",
    "encoder = tf.keras.models.Model(x, encoded)\n",
    "\n",
    "encoded_input = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "decoder_layer = autoencoder_tr.layers[-1]\n",
    "decoder = tf.keras.models.Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder_tr.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder_tr.fit(train_x, train_x,\n",
    "                epochs=100,\n",
    "                batch_size=449,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_x, test_x),\n",
    "                callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 115071 samples\n",
      "Epoch 1/72\n",
      "115071/115071 [==============================] - 1s 8us/sample - loss: 0.0785\n",
      "Epoch 2/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0733\n",
      "Epoch 3/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0723\n",
      "Epoch 4/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0719\n",
      "Epoch 5/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0716\n",
      "Epoch 6/72\n",
      "115071/115071 [==============================] - 1s 6us/sample - loss: 0.0713\n",
      "Epoch 7/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0711\n",
      "Epoch 8/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0710\n",
      "Epoch 9/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0709\n",
      "Epoch 10/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0708\n",
      "Epoch 11/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0707\n",
      "Epoch 12/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0706\n",
      "Epoch 13/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0706\n",
      "Epoch 14/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0705\n",
      "Epoch 15/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0705\n",
      "Epoch 16/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0704\n",
      "Epoch 17/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0704\n",
      "Epoch 18/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0704\n",
      "Epoch 19/72\n",
      "115071/115071 [==============================] - 1s 6us/sample - loss: 0.0703\n",
      "Epoch 20/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0703\n",
      "Epoch 21/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0703\n",
      "Epoch 22/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0703\n",
      "Epoch 23/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0702\n",
      "Epoch 24/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0702\n",
      "Epoch 25/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0702\n",
      "Epoch 26/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0701\n",
      "Epoch 27/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0701\n",
      "Epoch 28/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0700\n",
      "Epoch 29/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0700\n",
      "Epoch 30/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0700\n",
      "Epoch 31/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0699\n",
      "Epoch 32/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0699\n",
      "Epoch 33/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0699\n",
      "Epoch 34/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0699\n",
      "Epoch 35/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0699\n",
      "Epoch 36/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0698\n",
      "Epoch 37/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0698\n",
      "Epoch 38/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0698\n",
      "Epoch 39/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0698\n",
      "Epoch 40/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0698\n",
      "Epoch 41/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0698\n",
      "Epoch 42/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0698\n",
      "Epoch 43/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0697\n",
      "Epoch 44/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0697\n",
      "Epoch 45/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0697\n",
      "Epoch 46/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0697\n",
      "Epoch 47/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0697\n",
      "Epoch 48/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0697\n",
      "Epoch 49/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0697\n",
      "Epoch 50/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0696\n",
      "Epoch 51/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0696\n",
      "Epoch 52/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0696\n",
      "Epoch 53/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0696\n",
      "Epoch 54/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0696\n",
      "Epoch 55/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0695\n",
      "Epoch 56/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0695\n",
      "Epoch 57/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0695\n",
      "Epoch 58/72\n",
      "115071/115071 [==============================] - 1s 6us/sample - loss: 0.0695\n",
      "Epoch 59/72\n",
      "115071/115071 [==============================] - 1s 6us/sample - loss: 0.0695\n",
      "Epoch 60/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0694\n",
      "Epoch 61/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0694\n",
      "Epoch 62/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0694\n",
      "Epoch 63/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0694\n",
      "Epoch 64/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0694\n",
      "Epoch 65/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0694\n",
      "Epoch 66/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0694\n",
      "Epoch 67/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0693\n",
      "Epoch 68/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0693\n",
      "Epoch 69/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0693\n",
      "Epoch 70/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0693\n",
      "Epoch 71/72\n",
      "115071/115071 [==============================] - 1s 5us/sample - loss: 0.0692\n",
      "Epoch 72/72\n",
      "115071/115071 [==============================] - 1s 6us/sample - loss: 0.0692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b66b69348>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "\n",
    "x = tf.keras.Input(shape=(len(train_songs_df.columns),))\n",
    "\n",
    "encoded = tf.keras.layers.Dense(100,activation='relu')(x)\n",
    "encoded = tf.keras.layers.Dense(30,activation='relu')(encoded)\n",
    "encoded = tf.keras.layers.Dense(15,activation='relu')(encoded)\n",
    "\n",
    "decoded = tf.keras.layers.Dense(30,activation='relu')(encoded)\n",
    "decoded = tf.keras.layers.Dense(100,activation='relu')(decoded)\n",
    "decoded = tf.keras.layers.Dense(len(train_songs_df.columns),activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = tf.keras.models.Model(x,decoded)\n",
    "\n",
    "encoder = tf.keras.models.Model(x, encoded)\n",
    "\n",
    "encoded_input = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = tf.keras.models.Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(tr_songs, tr_songs,\n",
    "                epochs=72,\n",
    "                batch_size=449,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>id</th>\n",
       "      <th>plylst_title</th>\n",
       "      <th>songs</th>\n",
       "      <th>like_cnt</th>\n",
       "      <th>updt_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>118598</td>\n",
       "      <td></td>\n",
       "      <td>[373313, 151080, 275346, 696876, 165237, 52593...</td>\n",
       "      <td>1675</td>\n",
       "      <td>2019-05-27 14:14:33.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>131447</td>\n",
       "      <td>앨리스테이블</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-16 15:24:24.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>51464</td>\n",
       "      <td></td>\n",
       "      <td>[529437, 516103, 360067, 705713, 226062, 37089...</td>\n",
       "      <td>62</td>\n",
       "      <td>2008-06-21 23:26:22.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>45144</td>\n",
       "      <td></td>\n",
       "      <td>[589668, 21711, 570151, 320043, 13930, 599327,...</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-10-30 18:15:43.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>79929</td>\n",
       "      <td></td>\n",
       "      <td>[672718, 121924, 102694, 683657, 201558, 38511...</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-02-07 11:40:42.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23010</th>\n",
       "      <td>[잔잔한]</td>\n",
       "      <td>101722</td>\n",
       "      <td></td>\n",
       "      <td>[75842, 26083, 244183, 684715, 500593, 508608,...</td>\n",
       "      <td>17</td>\n",
       "      <td>2015-12-17 14:06:05.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23011</th>\n",
       "      <td>[어머니, 힘들때, 아빠, 가족, 위로받고싶을때]</td>\n",
       "      <td>122127</td>\n",
       "      <td></td>\n",
       "      <td>[450275, 487671, 561031, 663944, 628672, 59121...</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-04-16 21:35:44.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23012</th>\n",
       "      <td>[]</td>\n",
       "      <td>77438</td>\n",
       "      <td></td>\n",
       "      <td>[625875, 464051, 11657, 236393, 358186, 213435...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-27 15:27:40.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23013</th>\n",
       "      <td>[]</td>\n",
       "      <td>36231</td>\n",
       "      <td></td>\n",
       "      <td>[161094, 665833, 688145, 432735, 439938, 12665...</td>\n",
       "      <td>31</td>\n",
       "      <td>2015-11-18 11:49:09.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23014</th>\n",
       "      <td>[]</td>\n",
       "      <td>65189</td>\n",
       "      <td></td>\n",
       "      <td>[643070, 132994, 98223, 293236, 513129, 650494...</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-04-23 16:50:58.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23015 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tags      id plylst_title  \\\n",
       "0                               []  118598                \n",
       "1                               []  131447       앨리스테이블   \n",
       "2                               []   51464                \n",
       "3                               []   45144                \n",
       "4                               []   79929                \n",
       "...                            ...     ...          ...   \n",
       "23010                        [잔잔한]  101722                \n",
       "23011  [어머니, 힘들때, 아빠, 가족, 위로받고싶을때]  122127                \n",
       "23012                           []   77438                \n",
       "23013                           []   36231                \n",
       "23014                           []   65189                \n",
       "\n",
       "                                                   songs  like_cnt  \\\n",
       "0      [373313, 151080, 275346, 696876, 165237, 52593...      1675   \n",
       "1                                                     []         1   \n",
       "2      [529437, 516103, 360067, 705713, 226062, 37089...        62   \n",
       "3      [589668, 21711, 570151, 320043, 13930, 599327,...        20   \n",
       "4      [672718, 121924, 102694, 683657, 201558, 38511...        20   \n",
       "...                                                  ...       ...   \n",
       "23010  [75842, 26083, 244183, 684715, 500593, 508608,...        17   \n",
       "23011  [450275, 487671, 561031, 663944, 628672, 59121...        10   \n",
       "23012  [625875, 464051, 11657, 236393, 358186, 213435...         0   \n",
       "23013  [161094, 665833, 688145, 432735, 439938, 12665...        31   \n",
       "23014  [643070, 132994, 98223, 293236, 513129, 650494...        19   \n",
       "\n",
       "                     updt_date  \n",
       "0      2019-05-27 14:14:33.000  \n",
       "1      2014-07-16 15:24:24.000  \n",
       "2      2008-06-21 23:26:22.000  \n",
       "3      2017-10-30 18:15:43.000  \n",
       "4      2017-02-07 11:40:42.000  \n",
       "...                        ...  \n",
       "23010  2015-12-17 14:06:05.000  \n",
       "23011  2020-04-16 21:35:44.000  \n",
       "23012  2019-03-27 15:27:40.000  \n",
       "23013  2015-11-18 11:49:09.000  \n",
       "23014  2017-04-23 16:50:58.000  \n",
       "\n",
       "[23015 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[\"songs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cpu :  16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"Number of cpu : \", multiprocessing.cpu_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
